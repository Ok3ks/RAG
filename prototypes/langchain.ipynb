{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and API_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector, SemanticSimilarityExampleSelector, MaxMarginalRelevanceExampleSelector, ngram_overlap\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser,ResponseSchema,CommaSeparatedListOutputParser, PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'text-davinci-003'\n",
    "temperature = 0.3\n",
    "OPENAI_API_KEY = \"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\"\n",
    "model = OpenAI(model_name=model_name, temperature=temperature, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words from meaning with Langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The idea is to create a reverse lookup of a dictionary with langchain. Aims to solve the problem of uhm, what is that word that means xyz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = [ResponseSchema(name = \" Meaning\", description= \"Meaning supplied by the user\"),\n",
    "            ResponseSchema(name = \" Word\", description= \"Word that means the same as what the user supplied\")]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response) \n",
    "                #,CommaSeperatedListOutputParser(), PydanticOutputParser\n",
    "comma_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "#format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions = comma_parser.get_format_instructions()\n",
    "\n",
    "promt = PromptTemplate(template= \"\"\"Act as a reverse-dictionary, I will supply a meaning, and i want you to respond with only 1 word which corresponds to this \n",
    "                        \\n{Meaning} Do not respond with more than 1 word .\\n{format_instructions}\"\"\",\n",
    "    input_variables= [\"Meaning\"], partial_variables={\"format_instructions\": format_instructions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nonconformist', 'Unorthodox', 'Maverick.']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_input = promt.format_prompt(Meaning=\" Someone who opposes mainstream views for the sake of being different\")\n",
    "_input = promt.format(Meaning=\"Rare adjectives : Someone who opposes mainstream views for the sake of being different\")\n",
    "\n",
    "#[\"adjectives, noun, verbs\"]\n",
    "#[\"Rare words\", \"common words\"]\n",
    "#Add prompt, supply the noun version [ nouns, verbs,]\n",
    "\n",
    "output = model(_input)\n",
    "\n",
    "comma_parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Nonconformist, Eccentric, Unconventional.\n"
     ]
    }
   ],
   "source": [
    "meaning_to_words_chain = LLMChain(llm = model, prompt = promt)\n",
    "print(meaning_to_words_chain.run(\"Rare adjectives : Someone who opposes mainstream views for the sake of being different\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add meanings and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the words that best\n",
    "#Using examples for few shotprompt templating to create sentences\n",
    "#Create twitter bot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures of Speech from words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to create figures of speech(metaphors, simile, metonymy, Alliteration, antithesis, Epigram, Euphemism, Hyperbole, Litotes, Onomatopoeia, Oxymoron, Paradox, Personification, Pleonasm, Understatement), given a word. Also prompt to change context, or scenario of analogies(very imaginative), aimed to help writers be more creative with literary device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LiteraryDevice(BaseModel):\n",
    "    simile : List[str] = Field(description= \"Simile of the query\")\n",
    "    metaphors: List[str] = Field(description= \"Metaphor of the query\")\n",
    "    personification: List[str] = Field(description= \"Personification of the query \")\n",
    "    Alliteration: List[str] = Field(description= \"Alliteration of the query \")\n",
    "    Antithesis: List[str] = Field(description= \"Antithesis of the query\")\n",
    "    Oxymoron: List[str] = Field(description= \"Oxymoron of the query\")\n",
    "    Paradox: List[str] = Field(description= \"Paradox of the query\")\n",
    "    Litotes: List[str] = Field(description= \"Litotes of the query\")\n",
    "    #|Patwah:str = Field(description= \"Patwah like a Jamaican would\")\n",
    "    #UKEnglish:str = Field(description= \"Convert to UK street English slangs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = PydanticOutputParser(pydantic_object = LiteraryDevice)\n",
    "format_instructions_fig = output_parser.get_format_instructions()\n",
    "\n",
    "prompt_fig = PromptTemplate(\n",
    "    template=\"\"\"Create several figures of speech from this user's query \\n{words} .\\n{format_instructions} using this context {context}\"\"\",\n",
    "    input_variables= [\"words\"],\n",
    "    partial_variables= {\"format_instructions\": format_instructions_fig, \"context\": \"Greek history\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = input(\"Make it sweet sounding\")\n",
    "query = \"That was a quick shot from the footballer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\"simile\": [\"That was a lightning bolt from the footballer\", \"That was a flash in the pan from the footballer\", \"That was a shot in the dark from the footballer\"]}\n"
     ]
    }
   ],
   "source": [
    "figs_of_speech_chain = LLMChain(llm = model, prompt = prompt_fig)\n",
    "print(figs_of_speech_chain.run(query))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConstitutionalChain chain...\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mInitial response: \n",
      "\n",
      "Rebel.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mApplying count ...\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCritique: The model's response should only be one word, not a list of comma-separated values.\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mUpdated response: Rebel.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRebel.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "{\"simile\": \"Rebel like a Spartan warrior\", \"metaphors\": \"Rebel is a beacon of freedom\", \"personification\": \"Rebel stands defiantly against tyranny\", \"Alliteration\": \"Rebel rallies against the rulers\", \"Antithesis\": \"Rebel is the antithesis of oppression\", \"Oxymoron\": \"Rebel is a peaceful warrior\", \"Paradox\": \"Rebel is a revolutionary force of conformity\", \"Litotes\": \"Rebel is no ordinary soldier\"}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "{\"simile\": \"Rebel like a Spartan warrior\", \"metaphors\": \"Rebel is a beacon of freedom\", \"personification\": \"Rebel stands defiantly against tyranny\", \"Alliteration\": \"Rebel rallies against the rulers\", \"Antithesis\": \"Rebel is the antithesis of oppression\", \"Oxymoron\": \"Rebel is a peaceful warrior\", \"Paradox\": \"Rebel is a revolutionary force of conformity\", \"Litotes\": \"Rebel is no ordinary soldier\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain,ConstitutionalChain\n",
    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
    "\n",
    "count_principle = ConstitutionalPrinciple(\n",
    "                    name = \"count \",\n",
    "                    critique_request= \"should only have one output\",\n",
    "                    revision_request=\"Select the top ranked candidate\")\n",
    "\n",
    "#From scratching your head to finding the right word and figure of speech\n",
    "num_chain = ConstitutionalChain.from_llm(chain= meaning_to_words_chain,\n",
    "                                   constitutional_principles = [count_principle],\n",
    "                                   llm = model,\n",
    "                                   verbose = True)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains = [num_chain, figs_of_speech_chain],\n",
    "                                      verbose = True)\n",
    "\n",
    "magic = overall_chain.run(\"Someone who opposes mainstream views for the sake of being different\")\n",
    "print(magic)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    }
   ],
   "source": [
    "examples = [{\"in\": \"This is very beautiful and aesthetically appealing\",\"output\" :\"wavy\"},\n",
    "            {\"in\": \"That's alright, no problem at all\",\"output\" : \"Calm\"},\n",
    "            {\"in\" : \"I fully agree with you. spot on\", \"output\" : \"a hundred\"},\n",
    "            {\"in\" : \"That's a lie\", \"output\": \"big cap\"}]\n",
    "\n",
    "example_prompt = PromptTemplate(template= \"in : {input}\\nOutput: {output}\" ,\n",
    "                                input_variables= [\"input\", \"output\"]\n",
    "                                )\n",
    "#custom prompt template that explains inherits BasePromptTemplate BaseModel\n",
    "\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(examples, OpenAIEmbeddings(openai_api_key= OPENAI_API_KEY), \n",
    "                                                                   Chroma, K = 2)\n",
    "\n",
    "#example_selector.select_examplees({\"foo\": \"foo\"})\n",
    "\n",
    "dynamic_prompting = FewShotPromptTemplate(example_selector= example_selector,\n",
    "                                          example_prompt = example_prompt,\n",
    "                                          prefix= \"Convert this to english street slang\",\n",
    "                                          suffix= \"input: {query}\\nOutput:\",\n",
    "                                          input_variables=[\"query\"],\n",
    "                                          )\n",
    "\n",
    "#or custom example selector CustomExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = dynamic_prompting.format(query = \"Let's do something this sunday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Let's link up.\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(temp_input)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings = CohereEmbeddings()\n",
    "vectordb = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "vectordb.save_local('./vectordb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a caption bot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without multimodal input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_prompt_template = \"\"\" These are your instructions. What I require of you is to output captions for a descriptive text. I will not supply you an image just yet, but I will give you context, emotions I want viewers of this image\n",
    "                    to feel when they read the caption and view this image. Feel free to use any of the figures of speech available for literal effect. This could be similes, metaphors, personification, litotes, euphemism, exaggeration, puns, innuendos, hyperboles, alliterations or antithetical sentences. \n",
    "                    Another instruction is it the output should be a maximum of two lines. one line and two line captions are permitted.\n",
    "\n",
    "                    Now generate 2 caption for this text - \\n{text} in this context - \\n{context} with this format instructions {format_instructions}\"\"\"#teen_style\n",
    "\n",
    "caption_prompt_template_2 = \"\"\"These are your instructions, Convert the descriptive text into an haiku. Insert culture and use literary devices.\n",
    "                            Now generate a caption for this text - \\n{text} in this context - \\n{context} with this format instructions {format_instructions}    \"\"\"\n",
    "\n",
    "class captionGen(BaseModel):\n",
    "    caption : List[str] = Field(description= \"a 1-2 line caption for the descriptive text\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object= captionGen)\n",
    "\n",
    "format_instructions_fig = output_parser.get_format_instructions()\n",
    "\n",
    "caption_prompt = PromptTemplate(input_variables = ['text'], \n",
    "                                output_parser= output_parser, \n",
    "                                partial_variables = {\"format_instructions\" : format_instructions_fig, \"context\" : \"Brand copy\"},\n",
    "                                template = caption_prompt_template\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with zero shot prompting\n",
    "#https://www.jasper.ai/tools/instagram-caption-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHere is the output:\\n\\n{\"caption\": [\"Friends and family celebrating in joy, applauding and rejoicing in this moment.\", \"A moment of joy and bliss, shared by all in attendance.\"]}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_chain = LLMChain(llm = model, prompt = caption_prompt)\n",
    "\n",
    "caption_chain.run(\"\"\"\n",
    "                  Well wishers watching in adornment, clapping , jubilating and felicitating\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
